{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sentinelsat.readthedocs.io/en/stable/api_overview.html\n",
    "from sentinelsat import SentinelAPI, make_path_filter\n",
    "\n",
    "import requests\n",
    "from glob import glob\n",
    "from shapely.geometry import shape, mapping\n",
    "\n",
    "import geojson, json\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from rasterio.mask import mask\n",
    "\n",
    "import rasterio\n",
    "import rasterio.merge\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.plot import show, reshape_as_image\n",
    "from rasterio.warp import reproject, calculate_default_transform\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from numba import njit, prange\n",
    "\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tilecloud\n",
    "import gdal2tiles\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = ''\n",
    "password = ''\n",
    "\n",
    "with open('credentials') as file:\n",
    "    string = file.read()\n",
    "    username = string.split('\\n')[0].split('username=')[-1]\n",
    "    password = string.split('\\n')[1].split('password=')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon(osm_id):\n",
    "    \n",
    "    req = requests.get(url='https://nominatim.openstreetmap.org/lookup', params = {'osm_ids':'R{:}'.format(osm_id), 'format':'geojson','polygon_geojson':1}).json()\n",
    "\n",
    "    if len(req['features']) == 0:\n",
    "        requests.get('https://polygons.openstreetmap.fr/',\n",
    "        params={'id':osm_id})\n",
    "        geojson_req=requests.get('https://polygons.openstreetmap.fr/get_geojson.py',\n",
    "        params={'id':osm_id})\n",
    "        return shape(geojson_req.json())\n",
    "    \n",
    "    return shape(req['features'][0]['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_for_polygon_fix(city_name):\n",
    "    osm_relation_id = None\n",
    "    bbox = None\n",
    "    # Some cities needed hard coding at the time\n",
    "    # to get the correct polygons\n",
    "    if city_name == 'Albuquerque, New Mexico':\n",
    "        osm_relation_id = 171262\n",
    "    elif city_name == 'Cleveland, Ohio':\n",
    "        osm_relation_id = 182130\n",
    "    elif city_name == 'Columbia, Maryland':\n",
    "        osm_relation_id = 133606\n",
    "    elif city_name == 'Columbia, South Carolina':\n",
    "        osm_relation_id = 194000\n",
    "    elif city_name == 'Mesa, Arizona':\n",
    "        osm_relation_id = 110815\n",
    "    elif city_name == 'Pearl City, Hawaii':\n",
    "        osm_relation_id = 119264\n",
    "    elif city_name == 'San Bernardino, California':\n",
    "        osm_relation_id = 253639\n",
    "\n",
    "    if osm_relation_id != None:\n",
    "        geo = get_polygon(osm_relation_id)\n",
    "        bbox = geo.bounds\n",
    "\n",
    "    return osm_relation_id, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon_osm_relation_id_and_bbox(city_name):\n",
    "    \n",
    "    osm_relation_id, bbox = look_for_polygon_fix(city_name)\n",
    "\n",
    "    if bbox == None:\n",
    "        reqs=requests.get('https://nominatim.openstreetmap.org/search', params={\"q\": city_name, \"format\": \"geojson\"},)\n",
    "        for item in reqs.json()['features']:\n",
    "            if item['properties']['type']=='administrative' and item['properties']['category']=='boundary':\n",
    "                osm_relation_id = item['properties']['osm_id']\n",
    "                bbox = item['bbox']\n",
    "                break\n",
    "\n",
    "\n",
    "    bbox_tuple=(bbox[0], bbox[2], bbox[3], bbox[1])\n",
    "\n",
    "    return osm_relation_id, bbox_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pin_location_osm_relation_id(city_name):\n",
    "    \n",
    "    reqs=requests.get('https://nominatim.openstreetmap.org/search', params={\"q\": city_name, \"format\": \"geojson\"},)\n",
    "    for item in reqs.json()['features']:\n",
    "        if item['properties']['type']=='administrative' and item['properties']['category']=='admin_centre':\n",
    "            osm_relation_id = item['properties']['osm_id']\n",
    "            break\n",
    "\n",
    "    return osm_relation_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products(bbox_tuple, date, area_relation = 'Contains', limit = None):\n",
    "    api = SentinelAPI(username, password)\n",
    "    products=api.query('ENVELOPE{}'.format(bbox_tuple), \n",
    "        platformname='Sentinel-2',\n",
    "        processinglevel=\"Level-2A\",\n",
    "        limit = limit,  \n",
    "        area_relation = area_relation, \n",
    "        date=date)\n",
    "\n",
    "    if len(products)==0:\n",
    "        return None\n",
    "    \n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_images(products):\n",
    "    api = SentinelAPI(username, password)\n",
    "    api.download_all(products, directory_path='images/src', nodefilter=make_path_filter('*SCL_20m*.jp2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(products):\n",
    "    api = SentinelAPI(username, password)\n",
    "    paths = []\n",
    "    for folder in api.to_dataframe(products)['title']:\n",
    "        paths.append(glob('images/src/{:s}/**/**/**/**/*SCL_20m*.jp2'.format(folder+'.SAFE'))[0])\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(image_paths):\n",
    "    crs = rasterio.open(image_paths[0]).profile['crs']\n",
    "    img, affine = rasterio.merge.merge(image_paths)\n",
    "    memfile = MemoryFile()\n",
    "    image_file = memfile.open(driver='JP2OpenJPEG', height=img.shape[1], width=img.shape[2], count=img.shape[0], crs = crs, transform=affine, dtype=img.dtype)\n",
    "    image_file.write(img)\n",
    "    return image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_geo(geo, crs):\n",
    "    projection = pyproj.Transformer.from_proj(pyproj.Proj('EPSG:4326'), crs)\n",
    "    flip_coords = lambda x, y: (y,x)\n",
    "    if geo.geom_type != 'Polygon':\n",
    "        flipped_geo = [transform(flip_coords, polygon) for polygon in geo.geoms]\n",
    "    else:\n",
    "        flipped_geo = [transform(flip_coords, geo)]\n",
    "    return [transform(projection.transform, polygon) for polygon in flipped_geo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calc_highlight_fraction(image, to_highlight, compare_to):\n",
    "    highlighted = 0\n",
    "    comparison = 0\n",
    "    for y in prange(image.shape[1]):\n",
    "        for x in prange(image.shape[2]):\n",
    "            pixel = image[0, y, x]\n",
    "            if pixel in to_highlight:\n",
    "                highlighted += 1\n",
    "            elif pixel in compare_to:\n",
    "                comparison += 1\n",
    "    return highlighted/(highlighted+comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(image, to_highlight, with_alpha = True):\n",
    "    highlighted =  np.where(image == to_highlight, 255, 0)\n",
    "    if with_alpha:\n",
    "        return np.reshape(np.array([highlighted, highlighted]), newshape=(highlighted.shape[0]+1,highlighted.shape[1], highlighted.shape[2]))\n",
    "    return highlighted\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images(download = True):\n",
    "    all_products = []\n",
    "    product_map = {}\n",
    "    needs_attention_image = set()\n",
    "    needs_attention_osm = set()\n",
    "    image_paths = {}\n",
    "\n",
    "    if os.path.exists('product_map.json'):\n",
    "        image_paths = json.load(open('product_map.json'))\n",
    "        return image_paths, needs_attention_image, needs_attention_osm\n",
    "    \n",
    "    else:\n",
    "        city_data = json.load(open('city_data.json'))\n",
    "\n",
    "        for data in tqdm(city_data, desc='Preparing products'):\n",
    "            city_name = data['city']\n",
    "            start_date = date.fromisoformat(data['date'])\n",
    "            end_date = start_date + timedelta(days=1)\n",
    "            date_span = (start_date, end_date)\n",
    "\n",
    "            osm_id, bbox = get_polygon_osm_relation_id_and_bbox(city_name)\n",
    "            if osm_id == None or bbox == None:\n",
    "                needs_attention_osm.add(city_name)\n",
    "            else:    \n",
    "                products = get_products(bbox, date_span, area_relation = 'Contains', limit = 1)\n",
    "                if products == None:\n",
    "                    products = get_products(bbox, date_span, area_relation = 'Intersects')\n",
    "                    if products == None:\n",
    "                        needs_attention_image.add(city_name)\n",
    "                    else:\n",
    "                        product_map[city_name] = list(products)\n",
    "                        all_products.extend(list(products))\n",
    "                        image_paths[city_name] = get_image_paths(products)\n",
    "                else:\n",
    "                    product_map[city_name] = list(products)\n",
    "                    all_products.extend(list(products))\n",
    "                    image_paths[city_name] = get_image_paths(products)\n",
    "    \n",
    "    print('Ready: {:n}\\t Attention image: {:n}\\t Attention OSM: {:n}'.format(len(set(all_products)), len(needs_attention_image), len(needs_attention_osm)))\n",
    "    \n",
    "    with open('product_map.json', mode = 'w') as file:\n",
    "        file.write(geojson.dumps(image_paths, indent=4))\n",
    "    \n",
    "    if download:\n",
    "        download_all_images(all_products)\n",
    "\n",
    "    return image_paths, needs_attention_image, needs_attention_osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image(img, geometry, crop=True):\n",
    "    with rasterio.Env():\n",
    "        masked, affine = mask(img, geometry, crop=crop)\n",
    "        memfile = MemoryFile()\n",
    "        image_file = memfile.open(driver='JP2OpenJPEG', count=masked.shape[0], height=masked.shape[1], width=masked.shape[2], dtype=masked.dtype, crs=img.crs, transform=affine)\n",
    "        image_file.write(masked)\n",
    "        return image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_image(image, dst_crs='EPSG:3857'):\n",
    "    with rasterio.Env():\n",
    "        source = image.read()\n",
    "        dst_transform, height, width = calculate_default_transform(src_crs=image.crs, dst_crs=dst_crs, height=image.height, width=image.width, left=image.bounds.left, bottom=image.bounds.bottom, right=image.bounds.right, top=image.bounds.top)\n",
    "        \n",
    "        memfile = MemoryFile()\n",
    "        image_file = memfile.open(driver='JP2OpenJPEG', count=1, height=width, width=height, dtype=source.dtype, crs=dst_crs, transform=dst_transform)\n",
    "       \n",
    "        reproject(source=rasterio.band(image, 1), destination=rasterio.band(image_file, 1), src_crs=image.crs, dst_crs=dst_crs, src_transform=image.transform, dst_transform=dst_transform)\n",
    "\n",
    "        transformer = pyproj.Transformer.from_crs(crs_from=dst_crs, crs_to='EPSG:4326')\n",
    "        sn,we = transformer.transform([image_file.bounds[0],image_file.bounds[2]], [image_file.bounds[1],image_file.bounds[3]])\n",
    "\n",
    "        return image_file, (sn, we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = {\n",
    "    0: 'no_data',\n",
    "    1: 'saturated_or_defective',\n",
    "    2: 'dark_area_pixels',\n",
    "    3: 'cloud_shadows',\n",
    "    4: 'vegetation',\n",
    "    5: 'not_vegetated',\n",
    "    6: 'water',\n",
    "    7: 'unclassified',\n",
    "    8: 'cloud_medium_probability',\n",
    "    9: 'cloud_high_probability',\n",
    "    10: 'thin_cirrus',\n",
    "    11: 'snow'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(path):\n",
    "    if '/' in path:\n",
    "        child = path.split('/')[-1]\n",
    "        parent = path.split('/'+child)[0]\n",
    "        make_folder(parent)\n",
    "    if not os.path.isdir(path):\n",
    "            os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_city(city_name, paths, highlight_bands = [4, 5, 6]):\n",
    "    img = merge_images(paths)\n",
    "    osm_id, bbox = get_polygon_osm_relation_id_and_bbox(city_name)\n",
    "    geo = get_polygon(osm_id)\n",
    "\n",
    "    path = 'export/polygons'\n",
    "    make_folder(path)\n",
    "    with open('{:s}/{:s}.json'.format(path, city_name), mode = 'w') as file:\n",
    "        file.write(geojson.dumps(mapping(geo), indent=4))\n",
    "\n",
    "    usable_geo = get_transformed_geo(geo, img.profile['crs'])\n",
    "\n",
    "    masked_image = mask_image(img, usable_geo, crop=True)\n",
    "    reprojected, bounds = reproject_image(masked_image)\n",
    "    \n",
    "    coverages = {}\n",
    "\n",
    "    with rasterio.Env():\n",
    "        path = 'images/masked'\n",
    "        make_folder(path)\n",
    "        with rasterio.open('{:s}/{:s}.png'.format(path, city_name), mode='w', driver='PNG', count=1, height=reprojected.shape[0], width=reprojected.shape[1], crs=reprojected.profile['crs'], transform=reprojected.transform, dtype=np.uint8, compression='lzw') as file:\n",
    "                file.write(reprojected.read())\n",
    "        \n",
    "        for band in highlight_bands:\n",
    "            other_bands = highlight_bands.copy()\n",
    "            coverage_percent = calc_highlight_fraction(reprojected.read(), to_highlight=[band], compare_to=other_bands) * 100\n",
    "            band_name = BANDS[band]\n",
    "            coverages[band_name] = coverage_percent\n",
    "            highlighted = highlight(reprojected.read(), band)\n",
    "\n",
    "            path = 'images/processed/{:s}'.format(band_name)\n",
    "            make_folder(path)\n",
    "            with rasterio.open('{:s}/{:s}.png'.format(path, city_name) ,mode='w', driver='PNG', count=highlighted.shape[0], height=highlighted.shape[1], width=highlighted.shape[2], crs=reprojected.profile['crs'], transform=reprojected.transform, dtype=np.uint8, compression='lzw') as file:\n",
    "                file.write(highlighted)\n",
    "\n",
    "            path = 'export/masks/{:s}'.format(band_name)\n",
    "            make_folder(path)\n",
    "            Image.fromarray(np.array(reshape_as_image(highlighted), dtype=np.uint8)).save('{:s}/{:s}.png'.format(path, city_name))\n",
    "\n",
    "\n",
    "\n",
    "    return coverages, [*bounds[1], *bounds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    image_paths, _needs_attention_image, _needs_attention_osm = prepare_images(download = False)\n",
    "\n",
    "    processed = {}\n",
    "    bboxes = {}\n",
    "    \n",
    "    bands = np.arange(1, 11+1)\n",
    "    for city_name, paths in tqdm(image_paths.items(), desc='Processing'):\n",
    "        coverage, bbox_poly = process_city(city_name, paths, highlight_bands=bands)\n",
    "        processed[city_name] = coverage\n",
    "        bboxes[city_name] = bbox_poly\n",
    "\n",
    "    with open('export/coverage_percent_bands_{:}-{:}.json'.format(bands[0], bands[-1]), mode = 'w') as file:\n",
    "        file.write(geojson.dumps(processed, indent=4))\n",
    "\n",
    "    open('export/bbox.json', mode='w').write(json.dumps(bboxes, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def stack_image_arrays(image_1 : NDArray[np.uint8], image_2 : NDArray[np.uint8]) -> NDArray[np.uint8]:\n",
    "    combined_image = np.zeros(image_1.shape, dtype=image_1.dtype)\n",
    "    for y in prange(combined_image.shape[0]):\n",
    "        for x in range(combined_image.shape[1]):\n",
    "            for band in range(combined_image.shape[2]):\n",
    "                combined_image[y][x][band] = max(image_1[y][x][band], image_2[y][x][band])\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_image_tiles(image_path_1 : str, image_path_2 : str) -> NDArray[np.uint8]:\n",
    "    image_1 = np.array(Image.open(image_path_1))\n",
    "    image_2 = np.array(Image.open(image_path_2))\n",
    "    stacked = stack_image_arrays(image_1, image_2)\n",
    "\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_merge_tiles(tiles_path : str, export_path : str) -> None:\n",
    "    if not os.path.exists(export_path):\n",
    "        os.makedirs(export_path)\n",
    "    \n",
    "    files_in_tiles_path : list[str] = glob('*/*/*.png', root_dir=tiles_path)\n",
    "    files_in_export_path : list[str] = glob('*/*/*.png', root_dir=export_path)\n",
    "\n",
    "    for file_path in files_in_tiles_path:\n",
    "        existing_path : str | None = None\n",
    "        for existing_file_path in files_in_export_path:\n",
    "            if file_path == existing_file_path:\n",
    "                existing_path = existing_file_path\n",
    "        \n",
    "        if existing_path != None:\n",
    "            stacked_image = Image.fromarray(stack_image_tiles(tiles_path+file_path, export_path+file_path))\n",
    "            stacked_image.save(export_path+file_path)\n",
    "        else:\n",
    "            os.makedirs(export_path+file_path.replace(file_path.split('/')[-1].split('\\\\')[-1],''), exist_ok=True)\n",
    "            shutil.copy2(tiles_path+file_path, export_path+file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tiles(start_zoom=0, end_zoom=14, nb_processes=6, webviewer='none') -> None:\n",
    "    image_paths, _needs_attention_image, _needs_attention_osm = prepare_images(download = False)\n",
    "\n",
    "    first = True\n",
    "    for city_name, paths in tqdm(image_paths.items(), desc='Processing'):\n",
    "\n",
    "        bands = np.arange(1,11+1)\n",
    "        for band in bands:\n",
    "            band_name = BANDS[band]\n",
    "            path = 'images/processed/{:s}'.format(band_name)\n",
    "\n",
    "            gdal2tiles.generate_tiles('{:s}/{:s}.png'.format(path, city_name),\n",
    "                                      'export/tiles/separate/{:s}/{:s}/'.format(city_name, band_name),\n",
    "                                      zoom=[start_zoom, end_zoom],\n",
    "                                      resume=True,\n",
    "                                      title='SaTreeLight - {:s} - {:s}'.format(city_name, band_name), \n",
    "                                      nb_processes=nb_processes,\n",
    "                                      webviewer=webviewer,\n",
    "                                    )\n",
    "\n",
    "            copy_and_merge_tiles(tiles_path='export/tiles/separate/{:s}/{:s}/'.format(city_name, band_name), \n",
    "                                 export_path='export/tiles/merged/{:s}/'.format(band_name)\n",
    "                                )\n",
    "\n",
    "            if (first):\n",
    "                gdal2tiles.generate_tiles('{:s}/{:s}.png'.format(path, city_name),\n",
    "                                          'export/tiles/merged/{:s}/'.format(band_name),\n",
    "                                          zoom=[start_zoom, end_zoom],\n",
    "                                          resume=True,\n",
    "                                          title='SaTreeLight - {:s}'.format(band_name),\n",
    "                                          nb_processes=nb_processes,\n",
    "                                          webviewer=webviewer,\n",
    "                                        )\n",
    "        if (first):\n",
    "            first=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_tiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not worth further investigation, files get large/unparseable\n",
    "def polygonize_test():\n",
    "    from osgeo import gdal, ogr\n",
    "    raster = gdal.Open('images/processed/vegetation/Akron, Ohio.png')\n",
    "    band = raster.GetRasterBand(1)\n",
    "\n",
    "    if not os.path.exists('test/'):\n",
    "        os.makedirs('test')\n",
    "    out_file = 'test/akron.geojson'\n",
    "    if os.path.exists(out_file):\n",
    "        os.remove(out_file)\n",
    "    driver = ogr.GetDriverByName('GeoJson')\n",
    "    out_data_source = driver.CreateDataSource(out_file)\n",
    "    out_layer = out_data_source.CreateLayer('vegetation', srs=None)\n",
    "\n",
    "    new_field = ogr.FieldDefn('MYFLD', ogr.OFTInteger)\n",
    "    out_layer.CreateField(new_field)\n",
    "\n",
    "    gdal.Polygonize(band, None, out_layer, 0, [], callback=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abf5b559970227bffafeeb1e92c6309e7bf5511edab08f6972e92de672bc655b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
