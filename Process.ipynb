{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "from datetime import date, datetime, timedelta\n",
    "from glob import glob\n",
    "from typing import Callable, OrderedDict\n",
    "\n",
    "import geojson\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import rasterio\n",
    "import rasterio.merge\n",
    "import requests\n",
    "from affine import Affine\n",
    "from numba import njit, prange\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "from numpy.typing import NDArray\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.io import BufferedDatasetWriter, DatasetReader, DatasetWriter, MemoryFile\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import reshape_as_image, show\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "from requests import Response\n",
    "\n",
    "# https://sentinelsat.readthedocs.io/en/stable/api_overview.html\n",
    "from sentinelsat import SentinelAPI, make_path_filter\n",
    "from shapely.geometry import (\n",
    "    GeometryCollection,\n",
    "    LinearRing,\n",
    "    LineString,\n",
    "    MultiLineString,\n",
    "    MultiPoint,\n",
    "    MultiPolygon,\n",
    "    Point,\n",
    "    Polygon,\n",
    "    mapping,\n",
    "    shape,\n",
    ")\n",
    "from shapely.ops import transform\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=NumbaPendingDeprecationWarning)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import gdal2tiles\n",
    "from PIL import Image\n",
    "from tqdm.autonotebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare username and password\n",
    "username: str = \"\"\n",
    "password: str = \"\"\n",
    "\n",
    "with open(\"credentials\") as file:\n",
    "    string: str = file.read()\n",
    "    username = string.split(\"\\n\")[0].split(\"username=\")[-1]\n",
    "    password = string.split(\"\\n\")[1].split(\"password=\")[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon(\n",
    "    osm_id: int,\n",
    ") -> (\n",
    "    Point\n",
    "    | MultiPoint\n",
    "    | LineString\n",
    "    | MultiLineString\n",
    "    | Polygon\n",
    "    | MultiPolygon\n",
    "    | LinearRing\n",
    "    | GeometryCollection\n",
    "):\n",
    "    \"\"\"\n",
    "    Downloads and returns the geometry feature related to an OpenStreetMap\n",
    "    relation id.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        osm_id : int\n",
    "            The OpenStreetMap relation id to get geometry features from.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        feature : Point | MultiPoint | LineString | MultiLineString\n",
    "                    | Polygon | MultiPolygon | LinearRing | GeometryCollection\n",
    "            The geometry feature that is tied to the id.\n",
    "\n",
    "    \"\"\"\n",
    "    req = requests.get(\n",
    "        url=\"https://nominatim.openstreetmap.org/lookup\",\n",
    "        params={\n",
    "            \"osm_ids\": \"R{:}\".format(osm_id),\n",
    "            \"format\": \"geojson\",\n",
    "            \"polygon_geojson\": 1,\n",
    "        },\n",
    "    ).json()\n",
    "\n",
    "    if len(req[\"features\"]) == 0:\n",
    "        requests.get(\"https://polygons.openstreetmap.fr/\", params={\"id\": osm_id})\n",
    "        geojson_req: Response = requests.get(\n",
    "            \"https://polygons.openstreetmap.fr/get_geojson.py\", params={\"id\": osm_id}\n",
    "        )\n",
    "        return shape(geojson_req.json())\n",
    "\n",
    "    return shape(req[\"features\"][0][\"geometry\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_for_polygon_fix(city_name: str) -> tuple[int | None, tuple[float, ...] | None]:\n",
    "    \"\"\"\n",
    "    Looks for a hard coded fix for the city, if there is one.\n",
    "    These fixes were made as the query to the OpenStreetMap\n",
    "    services didn't yield the wanted polygon/relation id.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        city_name : str\n",
    "            The name of the city, with state.\n",
    "            Example format: \"Los Angeles, California\"\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        osm_relation : int | None\n",
    "            The corrected id, if there is one.\n",
    "\n",
    "        bbox : tuple[float, ...] | None\n",
    "            The bounding box for the corrected polygon,\n",
    "            if there is one.\n",
    "\n",
    "    \"\"\"\n",
    "    osm_id: int | None = None\n",
    "    bbox: tuple[float, ...] | None = None\n",
    "    # Some cities needed hard coding at the time\n",
    "    # to get the correct polygons\n",
    "    if city_name == \"Albuquerque, New Mexico\":\n",
    "        osm_id = 171262\n",
    "    elif city_name == \"Cleveland, Ohio\":\n",
    "        osm_id = 182130\n",
    "    elif city_name == \"Columbia, Maryland\":\n",
    "        osm_id = 133606\n",
    "    elif city_name == \"Columbia, South Carolina\":\n",
    "        osm_id = 194000\n",
    "    elif city_name == \"Mesa, Arizona\":\n",
    "        osm_id = 110815\n",
    "    elif city_name == \"Miami, Florida\":\n",
    "        osm_id = 1216769\n",
    "    elif city_name == \"Pearl City, Hawaii\":\n",
    "        osm_id = 119264\n",
    "    elif city_name == \"San Bernardino, California\":\n",
    "        osm_id = 253639\n",
    "\n",
    "    if osm_id != None:\n",
    "        geo: (\n",
    "            Point\n",
    "            | MultiPoint\n",
    "            | LineString\n",
    "            | MultiLineString\n",
    "            | Polygon\n",
    "            | MultiPolygon\n",
    "            | LinearRing\n",
    "            | GeometryCollection\n",
    "        ) = get_polygon(osm_id)\n",
    "        bbox = geo.bounds\n",
    "\n",
    "    return osm_id, bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon_osm_id_and_bbox(\n",
    "    city_name: str,\n",
    ") -> tuple[int | None, tuple[float, ...] | None]:\n",
    "    \"\"\"\n",
    "    Finds the OpenStreetMap polygon/relation id and\n",
    "    bounding box for the city polygon if one is found.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        city_name : str\n",
    "            The name of the city to query for.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        osm_id : int | None\n",
    "            The OpenStreetMap relation id for the\n",
    "            city polygon if one is found.\n",
    "\n",
    "         bbox : tuple[float, ...] | None\n",
    "            The bounding box for the city polygon,\n",
    "            if there is one.\n",
    "\n",
    "    \"\"\"\n",
    "    osm_id: int | None\n",
    "    bbox: tuple[float, ...] | None\n",
    "    osm_id, bbox = look_for_polygon_fix(city_name)\n",
    "\n",
    "    if bbox == None:\n",
    "        reqs: Response = requests.get(\n",
    "            \"https://nominatim.openstreetmap.org/search\",\n",
    "            params={\"q\": city_name, \"format\": \"geojson\"},\n",
    "        )\n",
    "        for item in reqs.json()[\"features\"]:\n",
    "            if (\n",
    "                item[\"properties\"][\"type\"] == \"administrative\"\n",
    "                and item[\"properties\"][\"category\"] == \"boundary\"\n",
    "            ):\n",
    "                osm_id = item[\"properties\"][\"osm_id\"]\n",
    "                bbox = item[\"bbox\"]\n",
    "                break\n",
    "\n",
    "    bbox_tuple: tuple[float, ...] | None = None\n",
    "    if bbox != None:\n",
    "        bbox_tuple = (bbox[0], bbox[2], bbox[3], bbox[1])\n",
    "\n",
    "    return osm_id, bbox_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pin_location_osm_id(city_name: str) -> int | None:\n",
    "    \"\"\"\n",
    "    Attempts to find an OpenStreetMap relation id for\n",
    "    a pin location for the city, if there is one.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        city_name : str\n",
    "            The name of the city to query for.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        osm_id : int | None\n",
    "            The OpenStreetMap relation id for the\n",
    "            city pin location if one is found.\n",
    "\n",
    "    \"\"\"\n",
    "    osm_id: int | None = None\n",
    "    reqs: Response = requests.get(\n",
    "        \"https://nominatim.openstreetmap.org/search\",\n",
    "        params={\"q\": city_name, \"format\": \"geojson\"},\n",
    "    )\n",
    "    for item in reqs.json()[\"features\"]:\n",
    "        if (\n",
    "            item[\"properties\"][\"type\"] == \"administrative\"\n",
    "            and item[\"properties\"][\"category\"] == \"admin_centre\"\n",
    "        ):\n",
    "            osm_id = item[\"properties\"][\"osm_id\"]\n",
    "            break\n",
    "\n",
    "    return osm_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products(\n",
    "    bbox: tuple[float, ...],\n",
    "    date: str | tuple[str | datetime | date, ...],\n",
    "    area_relation: str = \"Contains\",\n",
    "    limit: int | None = None,\n",
    ") -> OrderedDict | None:\n",
    "    \"\"\"\n",
    "    Gets the\n",
    "    Parameters\n",
    "    ---\n",
    "        bbox : tuple[float, ...]\n",
    "            The bounding box area to query within.\n",
    "\n",
    "        date : str | tuple[str | datatime | date, ...]\n",
    "            The date or date range to use when querying.\n",
    "\n",
    "        area_relation : {'Intersects', 'Contains', 'IsWithin'},\n",
    "            What relation to use for testing the AOI.\n",
    "\n",
    "        limit : int | None\n",
    "            Maximum number of products to get.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        products : OrderedDict | None\n",
    "            A dictionary that contains the info for the\n",
    "            found products, if any are found.\n",
    "\n",
    "    \"\"\"\n",
    "    api = SentinelAPI(username, password)\n",
    "    products: OrderedDict = api.query(\n",
    "        \"ENVELOPE{}\".format(bbox),\n",
    "        platformname=\"Sentinel-2\",\n",
    "        processinglevel=\"Level-2A\",\n",
    "        limit=limit,\n",
    "        area_relation=area_relation,\n",
    "        date=date,\n",
    "    )\n",
    "\n",
    "    if len(products) == 0:\n",
    "        return None\n",
    "\n",
    "    return products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_images(products: list[OrderedDict]) -> None:\n",
    "    \"\"\"\n",
    "    Download the images from all the listed products.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        products : list[OrderedDict]\n",
    "            The list of products to download.\n",
    "\n",
    "    \"\"\"\n",
    "    api: SentinelAPI = SentinelAPI(username, password)\n",
    "    api.download_all(\n",
    "        products,\n",
    "        directory_path=\"images/src\",\n",
    "        nodefilter=make_path_filter(\"*SCL_20m*.jp2\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(products: OrderedDict) -> list[str]:\n",
    "    \"\"\"\n",
    "    Gets the image paths for the product.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        products : OrderedDict\n",
    "            The product to get image paths for.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        paths : list[str]\n",
    "            The paths for the images.\n",
    "    \"\"\"\n",
    "    api: SentinelAPI = SentinelAPI(username, password)\n",
    "    paths: list[str] = []\n",
    "    for folder in api.to_dataframe(products)[\"title\"]:\n",
    "        paths.append(\n",
    "            glob(\"images/src/{:s}/**/**/**/**/*SCL_20m*.jp2\".format(folder + \".SAFE\"))[\n",
    "                0\n",
    "            ]\n",
    "        )\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(\n",
    "    image_paths: list[str],\n",
    ") -> DatasetReader | DatasetWriter | BufferedDatasetWriter:\n",
    "    \"\"\"\n",
    "    Merges images into one, useful if one image doesn't cover\n",
    "    the wanted area.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        image_paths : list[str]\n",
    "            The paths of the images to merge.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        image : DatasetReader | DatasetWriter | BufferedDatasetWriter\n",
    "            The merged image.\n",
    "\n",
    "    \"\"\"\n",
    "    crs: str | dict | CRS = rasterio.open(image_paths[0]).profile[\"crs\"]\n",
    "    image: np.ndarray\n",
    "    affine: Affine\n",
    "    image, affine = rasterio.merge.merge(image_paths)\n",
    "    memfile: MemoryFile = MemoryFile()\n",
    "    image_file: DatasetReader | DatasetWriter | BufferedDatasetWriter = memfile.open(\n",
    "        driver=\"JP2OpenJPEG\",\n",
    "        height=image.shape[1],\n",
    "        width=image.shape[2],\n",
    "        count=image.shape[0],\n",
    "        crs=crs,\n",
    "        transform=affine,\n",
    "        dtype=image.dtype,\n",
    "    )\n",
    "    image_file.write(image)\n",
    "    return image_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_geo(\n",
    "    geo: (\n",
    "        Point\n",
    "        | MultiPoint\n",
    "        | LineString\n",
    "        | MultiLineString\n",
    "        | Polygon\n",
    "        | MultiPolygon\n",
    "        | LinearRing\n",
    "        | GeometryCollection\n",
    "    ),\n",
    "    crs: str | dict | CRS,\n",
    ") -> list[\n",
    "    (\n",
    "        Point\n",
    "        | MultiPoint\n",
    "        | LineString\n",
    "        | MultiLineString\n",
    "        | Polygon\n",
    "        | MultiPolygon\n",
    "        | LinearRing\n",
    "        | GeometryCollection\n",
    "    )\n",
    "]:\n",
    "    \"\"\"\n",
    "    Transforms the geometry to a new crs/projection. We also need to\n",
    "    flip the coordinates first.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        geo : Point | MultiPoint | LineString | MultiLineString\n",
    "               | Polygon | MultiPolygon | LinearRing | GeometryCollection\n",
    "            The geometry to transform/reproject.\n",
    "\n",
    "        crs : str | dict | CRS\n",
    "            The target crs/projection.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        reproj_geo : Point | MultiPoint | LineString | MultiLineString\n",
    "                          | Polygon | MultiPolygon | LinearRing | GeometryCollection\n",
    "            The reprojected geometry.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    flip_coords: Callable[..., tuple] = lambda x, y: (y, x)\n",
    "    flipped_geo: list = []\n",
    "    if geo.geom_type != \"Polygon\":\n",
    "        flipped_geo = [transform(flip_coords, polygon) for polygon in geo.geoms]\n",
    "    else:\n",
    "        flipped_geo = [transform(flip_coords, geo)]\n",
    "\n",
    "    projection: pyproj.Transformer = pyproj.Transformer.from_proj(\n",
    "        pyproj.Proj(\"EPSG:4326\"), crs\n",
    "    )\n",
    "    transformed_geo: list[\n",
    "        (\n",
    "            Point\n",
    "            | MultiPoint\n",
    "            | LineString\n",
    "            | MultiLineString\n",
    "            | Polygon\n",
    "            | MultiPolygon\n",
    "            | LinearRing\n",
    "            | GeometryCollection\n",
    "        )\n",
    "    ] = [transform(projection.transform, polygon) for polygon in flipped_geo]\n",
    "    return transformed_geo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calc_highlight_fraction(\n",
    "    image: np.ndarray,\n",
    "    to_highlight: list[int],\n",
    "    compare_to: list[int],\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculates the fraction of the image which has a value\n",
    "    that is highlighted compared to the total of highlighted\n",
    "    and chosen comparison values.\n",
    "\n",
    "    `fraction = to_highlight / (to_highlight + compare_to)`\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        image : np.ndarray\n",
    "            The image to calculate from.\n",
    "\n",
    "        to_highlight : list[int]\n",
    "            The bands/values to find the fraction for.\n",
    "            The numerator of the fraction.\n",
    "\n",
    "        compare_to : list[int]\n",
    "            The bands/values to use in the denominator\n",
    "            together with `to_highlight`.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        fraction : float\n",
    "            The fraction of the image with\n",
    "            value in `to_highlight` compared to\n",
    "            the sum of `compare_to` and `to_highlight`.\n",
    "\n",
    "    \"\"\"\n",
    "    highlighted: int = 0\n",
    "    comparison: int = 0\n",
    "    for y in prange(image.shape[1]):\n",
    "        for x in prange(image.shape[2]):\n",
    "            pixel: int = image[0, y, x]\n",
    "            if pixel in to_highlight:\n",
    "                highlighted += 1\n",
    "            elif pixel in compare_to:\n",
    "                comparison += 1\n",
    "    return highlighted / (highlighted + comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(image:np.ndarray, to_highlight:int, with_alpha:bool = True,)->np.ndarray:\n",
    "    '''\n",
    "    Creates a highlighted version of the image, with only the highlighted value\n",
    "    as white/255 and the rest black/0. The rest can be made transparent with\n",
    "    the `with_alpha` parameter.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        image : np.ndarray\n",
    "            The image to highlight.\n",
    "\n",
    "        to_highlight : int\n",
    "            The band/value to highlight in the image.\n",
    "\n",
    "        with_alpha : bool\n",
    "            Whether to add an alpha layer with the same value\n",
    "            as the highlighted layer. This makes the parts\n",
    "            of the image that aren't highlighted transparent \n",
    "            instead of black/0.\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "        highlighted : np.ndarray\n",
    "            The highlighted image.\n",
    "        \n",
    "    '''\n",
    "    highlighted: np.ndarray =  np.where(image == to_highlight, 255, 0)\n",
    "    if with_alpha:\n",
    "        return np.reshape(np.array([highlighted, highlighted]), newshape=(highlighted.shape[0]+1,highlighted.shape[1], highlighted.shape[2]))\n",
    "    return highlighted\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images(\n",
    "    download: bool = True,\n",
    ") -> tuple[dict[str, list[str]], set[str], set[str]]:\n",
    "    \"\"\"\n",
    "    Prepares and finds the image products for the cities in `city_data.json`.\n",
    "    If `product_map.json` exists it will be loaded instead.\n",
    "    The images can be downloaded if `download` is true.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        download : bool\n",
    "            Whether to download the images.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        image_paths : dict[str, list[str]]\n",
    "            A dictionary of the cities with paths to their source images.\n",
    "\n",
    "        needs_attention_image : set[str]\n",
    "            A list of cities that has no source images.\n",
    "\n",
    "        needs_attention_osm : set[str]\n",
    "            A list of cities that has missing OpenStreetMap relation id\n",
    "            or bounding box.\n",
    "\n",
    "    \"\"\"\n",
    "    all_products: list[OrderedDict] = []\n",
    "    product_map: dict = {}\n",
    "    needs_attention_image: set[str] = set()\n",
    "    needs_attention_osm: set[str] = set()\n",
    "    image_paths: dict[str, list[str]] = {}\n",
    "\n",
    "    city_data: list[dict[str, str]] = json.load(open(\"city_data.json\"))\n",
    "\n",
    "    if os.path.exists(\"product_map.json\"):\n",
    "        image_paths = json.load(open(\"product_map.json\"))\n",
    "        if len(image_paths) == len(city_data):\n",
    "            return image_paths, needs_attention_image, needs_attention_osm\n",
    "\n",
    "    for data in tqdm(city_data, desc=\"Preparing products\"):\n",
    "        city_name: str = data[\"city\"]\n",
    "        start_date: date = date.fromisoformat(data[\"date\"])\n",
    "        end_date: date = start_date + timedelta(days=1)\n",
    "        date_span: tuple[date, date] = (start_date, end_date)\n",
    "\n",
    "        osm_id: int | None\n",
    "        bbox: tuple[float, ...] | None\n",
    "        osm_id, bbox = get_polygon_osm_id_and_bbox(city_name)\n",
    "\n",
    "        if osm_id == None or bbox == None:\n",
    "            needs_attention_osm.add(city_name)\n",
    "        else:\n",
    "            products: OrderedDict | None = get_products(\n",
    "                bbox, date_span, area_relation=\"Contains\", limit=1\n",
    "            )\n",
    "            if products == None:\n",
    "                products = get_products(bbox, date_span, area_relation=\"Intersects\")\n",
    "                if products == None:\n",
    "                    needs_attention_image.add(city_name)\n",
    "                else:\n",
    "                    product_map[city_name] = list(products)\n",
    "                    all_products.extend(list(products))\n",
    "                    image_paths[city_name] = get_image_paths(products)\n",
    "            else:\n",
    "                product_map[city_name] = list(products)\n",
    "                all_products.extend(list(products))\n",
    "                image_paths[city_name] = get_image_paths(products)\n",
    "\n",
    "    print(\n",
    "        \"Ready: {:n}\\t Attention image: {:n}\\t Attention OSM: {:n}\".format(\n",
    "            len(set(all_products)), len(needs_attention_image), len(needs_attention_osm)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    with open(\"product_map.json\", mode=\"w\") as file:\n",
    "        file.write(geojson.dumps(image_paths, indent=4))\n",
    "\n",
    "    if download:\n",
    "        download_all_images(all_products)\n",
    "\n",
    "    return image_paths, needs_attention_image, needs_attention_osm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_polygon_osm_id_and_bbox(\"Plano, Texas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image(\n",
    "    image: DatasetReader | DatasetWriter | BufferedDatasetWriter,\n",
    "    geometry: list[\n",
    "        (\n",
    "            Point\n",
    "            | MultiPoint\n",
    "            | LineString\n",
    "            | MultiLineString\n",
    "            | Polygon\n",
    "            | MultiPolygon\n",
    "            | LinearRing\n",
    "            | GeometryCollection\n",
    "        )\n",
    "    ],\n",
    "    crop=True,\n",
    ") -> DatasetReader | DatasetWriter | BufferedDatasetWriter:\n",
    "    \"\"\"\n",
    "    Masks the image with geometry.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        image : DatasetReader | DatasetWriter | BufferedDatasetWriter\n",
    "            The image to mask.\n",
    "\n",
    "        geometry : Point | MultiPoint | LineString | MultiLineString\n",
    "                         | Polygon | MultiPolygon | LinearRing | GeometryCollection\n",
    "            The geometry to mask the image with.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        masked_image : DatasetReader | DatasetWriter | BufferedDatasetWriter\n",
    "            The masked image.\n",
    "\n",
    "    \"\"\"\n",
    "    with rasterio.Env():\n",
    "        masked: np.ndarray\n",
    "        affine: Affine\n",
    "        masked, affine = mask(image, geometry, crop=crop)\n",
    "        memfile = MemoryFile()\n",
    "        image_file: DatasetReader | DatasetWriter | BufferedDatasetWriter = (\n",
    "            memfile.open(\n",
    "                driver=\"JP2OpenJPEG\",\n",
    "                count=masked.shape[0],\n",
    "                height=masked.shape[1],\n",
    "                width=masked.shape[2],\n",
    "                dtype=masked.dtype,\n",
    "                crs=image.crs,\n",
    "                transform=affine,\n",
    "            )\n",
    "        )\n",
    "        image_file.write(masked)\n",
    "        return image_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_image(\n",
    "    image: DatasetReader | DatasetWriter | BufferedDatasetWriter,\n",
    "    crs=\"EPSG:3857\",\n",
    ") -> tuple[\n",
    "    DatasetReader | DatasetWriter | BufferedDatasetWriter,\n",
    "    tuple[list[float], ...],\n",
    "]:\n",
    "    \"\"\"\n",
    "    Reprojects the image to the `crs`, usually the flat map EPSG:3857\n",
    "    projection (meters), and it's bounding box to the\n",
    "    ellipsoid/spheric EPSG:4326 (degrees).\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        image : DatasetReader | DatasetWriter | BufferedDatasetWriter\n",
    "            The image to reproject.\n",
    "\n",
    "        crs : str\n",
    "            The crs/projection to project to.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        reproj_image : DatasetReader | DatasetWriter | BufferedDatasetWriter\n",
    "            The reprojected image.\n",
    "\n",
    "        bbox : tuple[list[float], ...]\n",
    "            The bounding box for the reprojected image in EPSG:4326 (degrees).\n",
    "\n",
    "    \"\"\"\n",
    "    with rasterio.Env():\n",
    "        source: np.ndarray = image.read()\n",
    "        dst_transform, height, width = calculate_default_transform(\n",
    "            src_crs=image.crs,\n",
    "            dst_crs=crs,\n",
    "            height=image.height,\n",
    "            width=image.width,\n",
    "            left=image.bounds.left,\n",
    "            bottom=image.bounds.bottom,\n",
    "            right=image.bounds.right,\n",
    "            top=image.bounds.top,\n",
    "        )\n",
    "\n",
    "        memfile = MemoryFile()\n",
    "        image_file: DatasetReader | DatasetWriter | BufferedDatasetWriter = (\n",
    "            memfile.open(\n",
    "                driver=\"JP2OpenJPEG\",\n",
    "                count=1,\n",
    "                height=width,\n",
    "                width=height,\n",
    "                dtype=source.dtype,\n",
    "                crs=crs,\n",
    "                transform=dst_transform,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        reproject(\n",
    "            source=rasterio.band(image, 1),\n",
    "            destination=rasterio.band(image_file, 1),\n",
    "            src_crs=image.crs,\n",
    "            dst_crs=crs,\n",
    "            src_transform=image.transform,\n",
    "            dst_transform=dst_transform,\n",
    "        )\n",
    "\n",
    "        transformer: pyproj.Transformer = pyproj.Transformer.from_crs(\n",
    "            crs_from=crs, crs_to=\"EPSG:4326\"\n",
    "        )\n",
    "        sn: list[float]\n",
    "        we: list[float]\n",
    "        sn, we = transformer.transform(\n",
    "            [image_file.bounds[0], image_file.bounds[2]],\n",
    "            [image_file.bounds[1], image_file.bounds[3]],\n",
    "        )\n",
    "\n",
    "        return image_file, (sn, we)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The different bands that are available in the Sentinel-2\n",
    "# classified images.\n",
    "BANDS: dict[int, str] = {\n",
    "    0: \"no_data\",\n",
    "    1: \"saturated_or_defective\",\n",
    "    2: \"dark_area_pixels\",\n",
    "    3: \"cloud_shadows\",\n",
    "    4: \"vegetation\",\n",
    "    5: \"not_vegetated\",\n",
    "    6: \"water\",\n",
    "    7: \"unclassified\",\n",
    "    8: \"cloud_medium_probability\",\n",
    "    9: \"cloud_high_probability\",\n",
    "    10: \"thin_cirrus\",\n",
    "    11: \"snow\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(path) -> None:\n",
    "    \"\"\"\n",
    "    Creates the folder in path if it doesn't exist.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        path : str\n",
    "            The folder to create.\n",
    "\n",
    "    \"\"\"\n",
    "    if \"/\" in path:\n",
    "        child: str = path.split(\"/\")[-1]\n",
    "        parent: str = path.split(\"/\" + child)[0]\n",
    "        make_folder(parent)\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_city(\n",
    "    city_name: str,\n",
    "    paths: list[str],\n",
    "    highlight_bands=[4, 5, 6],\n",
    ") -> tuple[dict[str, float], list[float]] | None:\n",
    "    \"\"\"\n",
    "    Processes the city, i.e. creates masked image files\n",
    "    and calulates the coverage fractions for the\n",
    "    bands/values to highlight.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        city_name : str\n",
    "            The city to process.\n",
    "\n",
    "        paths : list[str]\n",
    "            The paths to the images for the city.\n",
    "\n",
    "        highlight_bands : list[int]\n",
    "            The bands/values to highlight in the images\n",
    "            and calculate fractions for.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        coverages : dict[str, float]\n",
    "            A dictionary with the coverage fractions\n",
    "            for each band/value in highlight_bands.\n",
    "\n",
    "        bbox : tuple[float, ...]\n",
    "            The bounding box for the city.\n",
    "\n",
    "    \"\"\"\n",
    "    image: DatasetReader | DatasetWriter | BufferedDatasetWriter = merge_images(paths)\n",
    "    osm_id: int | None\n",
    "    bbox: tuple[float, ...] | None\n",
    "    osm_id, bbox = get_polygon_osm_id_and_bbox(city_name)\n",
    "    if osm_id != None:\n",
    "        geo: (\n",
    "            Point\n",
    "            | MultiPoint\n",
    "            | LineString\n",
    "            | MultiLineString\n",
    "            | Polygon\n",
    "            | MultiPolygon\n",
    "            | LinearRing\n",
    "            | GeometryCollection\n",
    "        ) = get_polygon(osm_id)\n",
    "\n",
    "        path = \"export/polygons\"\n",
    "        make_folder(path)\n",
    "        with open(\"{:s}/{:s}.json\".format(path, city_name), mode=\"w\") as file:\n",
    "            file.write(geojson.dumps(mapping(geo), indent=4))\n",
    "\n",
    "        usable_geo: list[\n",
    "            (\n",
    "                Point\n",
    "                | MultiPoint\n",
    "                | LineString\n",
    "                | MultiLineString\n",
    "                | Polygon\n",
    "                | MultiPolygon\n",
    "                | LinearRing\n",
    "                | GeometryCollection\n",
    "            )\n",
    "        ] = get_transformed_geo(geo, image.profile[\"crs\"])\n",
    "\n",
    "        masked_image: DatasetReader | DatasetWriter | BufferedDatasetWriter = (\n",
    "            mask_image(image, usable_geo, crop=True)\n",
    "        )\n",
    "        reprojected: DatasetReader | DatasetWriter | BufferedDatasetWriter\n",
    "        bounds: tuple[list[float], ...]\n",
    "        reprojected, bounds = reproject_image(masked_image)\n",
    "\n",
    "        coverages: dict[str, float] = {}\n",
    "\n",
    "        with rasterio.Env():\n",
    "            path: str = \"images/masked\"\n",
    "            make_folder(path)\n",
    "            with rasterio.open(\n",
    "                \"{:s}/{:s}.png\".format(path, city_name),\n",
    "                mode=\"w\",\n",
    "                driver=\"PNG\",\n",
    "                count=1,\n",
    "                height=reprojected.shape[0],\n",
    "                width=reprojected.shape[1],\n",
    "                crs=reprojected.profile[\"crs\"],\n",
    "                transform=reprojected.transform,\n",
    "                dtype=np.uint8,\n",
    "                compression=\"lzw\",\n",
    "            ) as file:\n",
    "                file.write(reprojected.read())\n",
    "\n",
    "            for band in highlight_bands:\n",
    "                other_bands = highlight_bands.copy()\n",
    "                coverage_percent = (\n",
    "                    calc_highlight_fraction(\n",
    "                        reprojected.read(), to_highlight=[band], compare_to=other_bands\n",
    "                    )\n",
    "                    * 100\n",
    "                )\n",
    "                band_name: str = BANDS[band]\n",
    "                coverages[band_name] = coverage_percent\n",
    "                highlighted: np.ndarray = highlight(reprojected.read(), band)\n",
    "\n",
    "                path: str = \"images/processed/{:s}\".format(band_name)\n",
    "                make_folder(path)\n",
    "                with rasterio.open(\n",
    "                    \"{:s}/{:s}.png\".format(path, city_name),\n",
    "                    mode=\"w\",\n",
    "                    driver=\"PNG\",\n",
    "                    count=highlighted.shape[0],\n",
    "                    height=highlighted.shape[1],\n",
    "                    width=highlighted.shape[2],\n",
    "                    crs=reprojected.profile[\"crs\"],\n",
    "                    transform=reprojected.transform,\n",
    "                    dtype=np.uint8,\n",
    "                    compression=\"lzw\",\n",
    "                ) as file:\n",
    "                    file.write(highlighted)\n",
    "\n",
    "                path: str = \"export/masks/{:s}\".format(band_name)\n",
    "                make_folder(path)\n",
    "                Image.fromarray(\n",
    "                    np.array(reshape_as_image(highlighted), dtype=np.uint8)\n",
    "                ).save(\"{:s}/{:s}.png\".format(path, city_name))\n",
    "\n",
    "        return coverages, [*bounds[1], *bounds[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run() -> None:\n",
    "    \"\"\"\n",
    "    Calling this function will run the process for all the\n",
    "    cities found in `city_data.json`.\n",
    "\n",
    "    The results are saved in the `export` folder.\n",
    "\n",
    "    \"\"\"\n",
    "    image_paths: dict[str, list[str]]\n",
    "    needs_attention_image: set[str]\n",
    "    needs_attention_osm: set[str]\n",
    "    image_paths, needs_attention_image, needs_attention_osm = prepare_images(\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    if needs_attention_image or needs_attention_osm:\n",
    "        if needs_attention_image:\n",
    "            print(f\"These cities has image problems:\\n{needs_attention_image}\")\n",
    "\n",
    "        if needs_attention_osm:\n",
    "            print(f\"These cities has OSM problems:\\n{needs_attention_osm}\")\n",
    "\n",
    "        return\n",
    "\n",
    "    processed: dict[str, dict[str, float]] = {}\n",
    "    bboxes: dict[str, list[float]] = {}\n",
    "\n",
    "    bands: np.ndarray = np.arange(1, 11 + 1)\n",
    "\n",
    "    os.makedirs(\"tmp\", exist_ok=True)\n",
    "\n",
    "    tmp_coverage_file: str = f\"tmp/coverage_percent_bands_{bands[0]}-{bands[-1]}.json\"\n",
    "    tmp_bbox_file: str = \"tmp/bbox.json\"\n",
    "\n",
    "    coverage_file: str = f\"export/coverage_percent_bands_{bands[0]}-{bands[-1]}.json\"\n",
    "    bbox_file: str = \"export/bbox.json\"\n",
    "\n",
    "    if os.path.exists(tmp_coverage_file):\n",
    "        processed = geojson.load(open(tmp_coverage_file))\n",
    "\n",
    "    if os.path.exists(tmp_bbox_file):\n",
    "        bboxes = geojson.load(open(tmp_bbox_file))\n",
    "\n",
    "    progressbar: tqdm = tqdm(total=len(image_paths.items()), desc=\"Processing\")\n",
    "\n",
    "    for city_name, paths in image_paths.items():\n",
    "        progressbar.set_postfix(city=city_name, refresh=True)\n",
    "        if city_name in processed.keys() and city_name in bboxes.keys():\n",
    "            progressbar.update(1)\n",
    "            continue\n",
    "\n",
    "        processed_city: tuple[dict[str, float], list[float]] | None = process_city(\n",
    "            city_name, paths, highlight_bands=bands\n",
    "        )\n",
    "        if processed_city != None:\n",
    "            coverage: dict[str, float] = processed_city[0]\n",
    "            bbox_poly: list[float] = processed_city[1]\n",
    "            processed[city_name] = coverage\n",
    "            bboxes[city_name] = bbox_poly\n",
    "\n",
    "        open(tmp_coverage_file, mode=\"w\").write(\n",
    "            geojson.dumps(\n",
    "                processed,\n",
    "                indent=4,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        open(tmp_bbox_file, mode=\"w\").write(\n",
    "            json.dumps(\n",
    "                bboxes,\n",
    "                indent=4,\n",
    "            )\n",
    "        )\n",
    "        progressbar.update(1)\n",
    "\n",
    "    open(coverage_file, mode=\"w\").write(\n",
    "        geojson.dumps(\n",
    "            processed,\n",
    "            indent=4,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    open(bbox_file, mode=\"w\").write(\n",
    "        json.dumps(\n",
    "            bboxes,\n",
    "            indent=4,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    os.remove(tmp_coverage_file)\n",
    "    os.remove(tmp_bbox_file)\n",
    "    os.rmdir(\"tmp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def stack_image_arrays(\n",
    "    image_1: NDArray[np.uint8],\n",
    "    image_2: NDArray[np.uint8],\n",
    ") -> NDArray[np.uint8]:\n",
    "    \"\"\"\n",
    "    Stacks two images on top of each other. The highest pixel\n",
    "    value is kept at each position.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        image_1 : np.ndarray[np.uint8]\n",
    "            The first image to stack.\n",
    "\n",
    "        image_2 : np.ndarray[np.uint8]\n",
    "            The second image to stack.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        combined_image : np.ndarray[np.uint8]\n",
    "            The combined stacked image.\n",
    "\n",
    "    \"\"\"\n",
    "    combined_image: np.ndarray = np.zeros(image_1.shape, dtype=image_1.dtype)\n",
    "    for y in prange(combined_image.shape[0]):\n",
    "        for x in range(combined_image.shape[1]):\n",
    "            for band in range(combined_image.shape[2]):\n",
    "                combined_image[y][x][band] = max(\n",
    "                    image_1[y][x][band], image_2[y][x][band]\n",
    "                )\n",
    "\n",
    "    return combined_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_image_tiles(\n",
    "    image_path_1: str,\n",
    "    image_path_2: str,\n",
    ") -> NDArray[np.uint8]:\n",
    "    \"\"\"\n",
    "    Stacks the images from the given paths. Calls `stack_image_arrays`.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        image_path_1 : str\n",
    "            Path to the first image of the stack.\n",
    "\n",
    "        image_path_2 : str\n",
    "            Path to the second image of the stack.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        stacked : np.ndarray[np.uint8]\n",
    "            The stacked image.\n",
    "\n",
    "    \"\"\"\n",
    "    image_1: np.ndarray = np.array(Image.open(image_path_1))\n",
    "    image_2: np.ndarray = np.array(Image.open(image_path_2))\n",
    "    stacked: np.ndarray = stack_image_arrays(image_1, image_2)\n",
    "\n",
    "    return stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_merge_tiles(\n",
    "    tiles_path: str,\n",
    "    export_path: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Copies and merges tiles for all the tiles found\n",
    "    in the given path.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        tiles_path : str\n",
    "            Where the tiles are stored.\n",
    "\n",
    "        export_path : str\n",
    "            Where to save the merged tiles.\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(export_path):\n",
    "        os.makedirs(export_path)\n",
    "\n",
    "    files_in_tiles_path: list[str] = glob(\"*/*/*.png\", root_dir=tiles_path)\n",
    "    files_in_export_path: list[str] = glob(\"*/*/*.png\", root_dir=export_path)\n",
    "\n",
    "    for file_path in files_in_tiles_path:\n",
    "        existing_path: str | None = None\n",
    "        for existing_file_path in files_in_export_path:\n",
    "            if file_path == existing_file_path:\n",
    "                existing_path = existing_file_path\n",
    "\n",
    "        if existing_path != None:\n",
    "            stacked_image: Image.Image = Image.fromarray(\n",
    "                stack_image_tiles(tiles_path + file_path, export_path + file_path)\n",
    "            )\n",
    "            stacked_image.save(export_path + file_path)\n",
    "        else:\n",
    "            os.makedirs(\n",
    "                export_path\n",
    "                + file_path.replace(file_path.split(\"/\")[-1].split(\"\\\\\")[-1], \"\"),\n",
    "                exist_ok=True,\n",
    "            )\n",
    "            shutil.copy2(tiles_path + file_path, export_path + file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tiles(\n",
    "    start_zoom=0,\n",
    "    end_zoom=14,\n",
    "    nb_processes=6,\n",
    "    webviewer=\"none\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Makes map tiles from the processed images.\n",
    "    The tiles are both separate for each city\n",
    "    and band/class as well as combined to\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "        start_zoom : int\n",
    "            The farthest zoom distance to make tiles for.\n",
    "\n",
    "        end_zoom : int\n",
    "            The closest zoom distance to make tiles for.\n",
    "\n",
    "        nb_processes : int\n",
    "            The number of threads to use for processing.\n",
    "\n",
    "        webviewer : {'all', 'google', 'openlayers', 'none'}\n",
    "            Which webviewer maps to generate preview html files for.\n",
    "\n",
    "    \"\"\"\n",
    "    image_paths: dict[str, list[str]]\n",
    "    needs_attention_image: set[str]\n",
    "    needs_attention_osm: set[str]\n",
    "    image_paths, needs_attention_image, needs_attention_osm = prepare_images(\n",
    "        download=False\n",
    "    )\n",
    "\n",
    "    if needs_attention_image or needs_attention_osm:\n",
    "        if needs_attention_image:\n",
    "            print(f\"These cities has image problems:\\n{needs_attention_image}\")\n",
    "\n",
    "        if needs_attention_osm:\n",
    "            print(f\"These cities has OSM problems:\\n{needs_attention_osm}\")\n",
    "\n",
    "        return\n",
    "\n",
    "    first = True\n",
    "    for city_name, paths in tqdm(image_paths.items(), desc=\"Processing\"):\n",
    "        bands: np.ndarray = np.arange(1, 11 + 1)\n",
    "        for band in bands:\n",
    "            band_name: str = BANDS[band]\n",
    "            path: str = \"images/processed/{:s}\".format(band_name)\n",
    "\n",
    "            gdal2tiles.generate_tiles(\n",
    "                \"{:s}/{:s}.png\".format(path, city_name),\n",
    "                \"export/tiles/separate/{:s}/{:s}/\".format(city_name, band_name),\n",
    "                zoom=[start_zoom, end_zoom],\n",
    "                resume=True,\n",
    "                title=\"SaTreeLight - {:s} - {:s}\".format(city_name, band_name),\n",
    "                nb_processes=nb_processes,\n",
    "                webviewer=webviewer,\n",
    "            )\n",
    "\n",
    "            copy_and_merge_tiles(\n",
    "                tiles_path=\"export/tiles/separate/{:s}/{:s}/\".format(\n",
    "                    city_name, band_name\n",
    "                ),\n",
    "                export_path=\"export/tiles/merged/{:s}/\".format(band_name),\n",
    "            )\n",
    "\n",
    "            if first:\n",
    "                gdal2tiles.generate_tiles(\n",
    "                    \"{:s}/{:s}.png\".format(path, city_name),\n",
    "                    \"export/tiles/merged/{:s}/\".format(band_name),\n",
    "                    zoom=[start_zoom, end_zoom],\n",
    "                    resume=True,\n",
    "                    title=\"SaTreeLight - {:s}\".format(band_name),\n",
    "                    nb_processes=nb_processes,\n",
    "                    webviewer=webviewer,\n",
    "                )\n",
    "        if first:\n",
    "            first = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not worth further investigation, files get large/unparseable\n",
    "# This was an attempt at trying to make polygons from the raster\n",
    "# images, but wasn't found to be feasible.\n",
    "def polygonize_test():\n",
    "    from osgeo import gdal, ogr\n",
    "\n",
    "    raster = gdal.Open(\"images/processed/vegetation/Akron, Ohio.png\")\n",
    "    band = raster.GetRasterBand(1)\n",
    "\n",
    "    if not os.path.exists(\"test/\"):\n",
    "        os.makedirs(\"test\")\n",
    "    out_file = \"test/akron.geojson\"\n",
    "    if os.path.exists(out_file):\n",
    "        os.remove(out_file)\n",
    "    driver = ogr.GetDriverByName(\"GeoJson\")\n",
    "    out_data_source = driver.CreateDataSource(out_file)\n",
    "    out_layer = out_data_source.CreateLayer(\"vegetation\", srs=None)\n",
    "\n",
    "    new_field = ogr.FieldDefn(\"MYFLD\", ogr.OFTInteger)\n",
    "    out_layer.CreateField(new_field)\n",
    "\n",
    "    gdal.Polygonize(band, None, out_layer, 0, [], callback=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abf5b559970227bffafeeb1e92c6309e7bf5511edab08f6972e92de672bc655b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
